<link rel="shortcut icon" type="image/png" href="favicon.ico"/>
<link rel="stylesheet" Type="text/css" href="http://people.virginia.edu/~nj7kv/style.css">
<title>The Control Problem</title>

### The Control Problem

From the sixth century to February 9th, 1996, we were the undisputed masters of chess. If you wanted to see the best chess matches, they would be played solely between humans. The next day, a computer by the name of Deep Blue bested the reigning grandmaster, Gary Kasparov, in a match. Kasparov went on to successfully beat the computer 4-2, but lost the following year to its next iteration (hilariously named Deeper Blue). On February 10th, humanity's top billing as chess players was questioned. Just 15 months later, computers rose to the top of the totem pole, and show no signs of relinquishing that throne. Humans still play each other in chess tournaments, but their playstyles are heavily influenced by computer analysis, so much so that deviations from computed predictions are closely scrutinized, and often found to be blunders. The student has become the teacher, or perhaps more accurately, the calculator has become the mathematician.

Believe it or not, Deep Blue and its chess-playing kin are actually a form of artificial intelligence. While AIs in popular culture often take the form of murderous robots or godlike beings, they are currently understood to come in three different flavors: weak, strong, and super. Chess programs are a type of _weak_ AI - programs that may outperform humans in a single task, but fail at accomplishing the wide range of tasks we can. They aren't general purpose, but are specialized. Think spam filters, virtual assistants, and that smart thermostat you might already have in your home. And if you look at the rate at which consumer-ready weak AI is becoming available, it becomes clear that we're at the start of an AI boom.

And only a technophobe would be scared of an AI boom, right? Nobody likes spam, Siri is almost laughably bad[^fn1], and intelligently adjusting temperature sounds utterly benign. With these examples as a backdrop, claiming that Deep Blue and it's ilk will spell our demise probably sounds like fear mongering. [But as others have pointed out][Humans Need Not Apply] the economic problems associated with automation will become apparent way before all human labor is made irrelevant. Computers don't have to replace humans in all industries. This can be seen most clearly with [self driving cars][Self Driving Hyundai]. No longer confined to the realm of thought experiments and science fiction, autonomous vehicles are poised to swallow a significant amount of transportation jobs. This does not bode well for the nearly 4.4 million people currently employed by the transportation industry.[^fn2]

That's certainly ominous, but predictable; technology almost always eliminates at least some jobs. And if you're like me, then predictable = boring. Let's get theoretical and dive into strong AI. Simply, strong AI is defined as a program that can operate indistinguishably from a human at a wide range of tasks.[^fn3] The key distinction between weak and strong AI is their versatility. Your self driving car may be as good as a human driver, but you can't just stick a driving AI into your phone and use it as a voice assistant. And while weak AI would gradually pick off small subsets of jobs, strong AI would rapidly eliminate entire industries. 

No strong AI currently exist, and most advances in the field have been incremental upgrades to weak AI. However, two different solutions show promise. The simplest and straightforward method would be **whole brain emulation** (WBE). This involves comprehensively scanning a biological brain and then closely modeling it. Despite being barefaced plagiarism, WBE has one key advantage; it requires no understanding of human cognition or artificial intelligence. Because no fundamental breakthrough or proof of concept has to be achieved, the obstacles WBE faces are more practical in nature. Three different technical feats must be conquered: high throughput scanning, automated image analysis, and implementation-ready hardware. In simpler terms, we have to be able to scan the brain in enough detail to be able to recreate it, process all the data generated by that scan, and use that data to run a simulation on a computer that won't immediately burst into flames.

Such a brute force approach has much to reccomend it, but a more efficient approach also exits. We know that evolution, while slow and blind, can create intelligence at least as smart as humans because, well, here we are. If a programmer can harness and guide evolutionary processes, as opposed to random chance, it should be possible to create intelligent life far more quickly than evolution created us. _**Compare birds and humans building airplanes**_ 

Economic collapse is definitely something to worry about, but ranks pretty low on the "sexiest ways to destroy a civilization" list. ^_citation_^ ^_needed_^  Let's talk about super AI.

[^fn1]: At least at the time of writing
[^fn2]: [Buereau of Labor Statsitics][Labor Stats]
[^fn3]: [Intelligence.org][AGI]

[Office Space]: https://www.youtube.com/watch?v=fjsSr3z5nVk
[Humans Need Not Apply]: https://www.youtube.com/watch?v=7Pq-S557XQU
[Self Driving Hyundai]: https://www.youtube.com/watch?v=EPTIXldrq3Q
[Labor Stats]: https://www.bls.gov/emp/ep_table_201.htm
[AGI]: https://intelligence.org/2013/08/11/what-is-agi/
